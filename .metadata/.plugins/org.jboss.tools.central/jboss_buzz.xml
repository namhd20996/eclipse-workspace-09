<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>How to create a workspace via Try in Dev Spaces extension</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/22/how-create-workspace-try-dev-spaces-extension" /><author><name>David Kwon</name></author><id>f1be340e-5e44-46ce-9bee-d5eefdcccf6c</id><updated>2023-06-22T07:00:00Z</updated><published>2023-06-22T07:00:00Z</published><summary type="html">&lt;p&gt;In early June, we released a new web extension for Red Hat OpenShift Dev Spaces called &lt;a href="https://redhat-developer.github.io/try-in-dev-spaces-browser-extension/"&gt;Try in Dev Spaces&lt;/a&gt;. Version 1.0 of the extension is available for Chromium-based browsers (Google Chrome, Microsoft Edge, Brave, Opera, etc.), Safari, and Firefox.&lt;/p&gt; &lt;p&gt;You can download the web extension from these marketplaces:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/try-in-dev-spaces/gbookaeilomckmoofeocnkfidfeendan"&gt;Chrome Web Store&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://apps.apple.com/us/app/try-in-dev-spaces/id6446597744"&gt;Mac App Store&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/try-in-dev-spaces/"&gt;Firefox Browser Add-ons&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How to use the Try in Dev Spaces web extension&lt;/h2&gt; &lt;p&gt;Are you new to OpenShift Dev Spaces? Try it for free in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This extension provides a &lt;strong&gt;Dev Spaces&lt;/strong&gt; button in the GitHub project page that creates and opens a new workspace with the GitHub project on an OpenShift Dev Spaces installation (Figure 1). OpenShift Dev Spaces is a platform for creating reproducible, container-based cloud development environments (or workspaces) for your Git projects on Red Hat OpenShift. In a workspace, you can code, build, test, and deploy your application within an OpenShift cluster.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/btn-and-dropdown.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/btn-and-dropdown.jpg?itok=q1n9ytN2" width="1100" height="380" alt="The 'Dev Spaces' button within the GitHub UI and the button's dropdown items displaying different Dev Spaces instances/" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1. Screenshots of the extension's Dev Spaces button within the GitHub UI.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;By default the web extension opens the GitHub project on the free OpenShift Dev Spaces instance accessible on the Developer Sandbox for Red Hat OpenShift. However, additional Dev Spaces instances (or upstream Eclipse Che instances) for creating workspaces can also be configured. Configuring different Dev Spaces instances is done in the extension’s options page. The &lt;strong&gt;Dev Spaces&lt;/strong&gt; button provides a dropdown menu, allowing you to select which OpenShift Dev Spaces installation you want to create the workspace.&lt;/p&gt; &lt;p&gt;Figure 2 shows a quick demo of the extension in action. In the demo, we add a new Dev Spaces instance in the extension’s options, and start a new workspace on the newly added instance with the new &lt;strong&gt;Dev Spaces&lt;/strong&gt; button on GitHub.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/quick-demo.gif"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/quick-demo.gif" width="1600" height="1060" alt="A demo of how to use the Dev Spaces button, adding new Dev Spaces endpoint and creating a workspace." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2. A demo of how to use the Dev Spaces button. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How does the Dev Spaces button work?&lt;/h2&gt; &lt;p&gt;If you have worked with OpenShift Dev Spaces (or the upstream project Eclipse Che®) before, you may already know that you can create workspaces by constructing and accessing a custom URL.&lt;/p&gt; &lt;p&gt;The custom URL consists of at least two main parts. There can be more parts if you want to customize the workspace further with &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_dev_spaces/3.4/html/user_guide/user-onboarding#optional-parameters-for-the-urls-for-starting-a-new-workspace"&gt;URL parameters&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 3 displays a simple example of creating a new workspace with the &lt;code&gt;https://github.com/&lt;user&gt;/&lt;repo&gt;&lt;/code&gt; repository on the imaginary &lt;code&gt;https://devspaces.example.com&lt;/code&gt; Dev Spaces instance.&lt;/p&gt; &lt;p&gt;For a concrete example, try accessing &lt;code&gt;https://workspaces.openshift.com/#https://github.com/che-incubator/quarkus-api-example&lt;/code&gt; to create a new workspace on the Developer Sandbox for Red Hat OpenShift using the &lt;code&gt;https://github.com/che-incubator/quarkus-api-example&lt;/code&gt; GitHub project.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/URL.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/URL.png?itok=fTXrCTAc" width="600" height="138" alt="Example of a URL to create a new Dev Spaces workspace." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3. The URL used to create a new workspace in OpenShift Dev Spaces.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Clicking the &lt;strong&gt;Dev Spaces&lt;/strong&gt; button is essentially just accessing a custom-made URL. As the customization options for the URL grows, creating the custom URL by hand can be more time-consuming. The button is there for convenience, constructing URLs so you don’t have to.&lt;/p&gt; &lt;h2&gt;Installing the web extension on an air-gapped environment&lt;/h2&gt; &lt;p&gt;You can download the web extension’s source code from the &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension"&gt;GitHub repository&lt;/a&gt;, build and sideload it into your browser.&lt;/p&gt; &lt;p&gt;To build the extension, run the following on a non-air-gapped machine:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ git clone https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/tree/v1.0.0 $ cd try-in-dev-spaces-browser-extension/ $ yarn $ yarn build:prod # build the extension for Chromium based browsers $ yarn build:prod-sf # build the extension for Safari and Firefox&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can find the built extension for Chromium-based browsers in &lt;code&gt;dist/chromium&lt;/code&gt; and the extension built for Safari and Firefox in &lt;code&gt;dist/safari-firefox&lt;/code&gt;. Copy the built extension to the air-gapped machine and sideload the extension to the web browser by following the browser-specific steps from this &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/blob/main/CONTRIBUTING.md"&gt;document&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Upcoming plans for Try in Dev Spaces&lt;/h2&gt; &lt;p&gt;We plan to expand the extension's functionality by adding support for Azure DevOps Services, GitLab, and BitBucket in a future release. Additionally, we will make it easier to configure the created workspace using URL parameters (e.g., automatically setting up Git remotes when starting a workspace from a forked repository). If you have a question, please &lt;a href="https://github.com/redhat-developer/try-in-dev-spaces-browser-extension/issues/new"&gt;create an issue&lt;/a&gt; in the GitHub repository. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/22/how-create-workspace-try-dev-spaces-extension" title="How to create a workspace via Try in Dev Spaces extension"&gt;How to create a workspace via Try in Dev Spaces extension&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>David Kwon</dc:creator><dc:date>2023-06-22T07:00:00Z</dc:date></entry><entry><title>New C++ features in GCC 13</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/21/new-c-features-gcc-13" /><author><name>Marek Polacek</name></author><id>0f8eb019-7e52-4ecf-9eac-a7e573abcde8</id><updated>2023-06-21T07:00:00Z</updated><published>2023-06-21T07:00:00Z</published><summary type="html">&lt;p&gt;The latest major version of the &lt;a href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC), 13.1, was released in April 2023. Like every major GCC release, this version brings many&lt;a href="https://gcc.gnu.org/gcc-13/changes.html"&gt; additions, improvements, bug fixes, and new features&lt;/a&gt;. GCC 13 is already the system compiler in&lt;a href="https://fedoraproject.org/wiki/Changes/GNUToolchainF38"&gt; Fedora 38&lt;/a&gt;. &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) users will get GCC 13 in the Red Hat GCC Toolset (RHEL 8 and RHEL 9). It's also possible to try GCC 13 on &lt;a href="https://godbolt.org/"&gt;godbolt.org&lt;/a&gt; and similar web pages.&lt;/p&gt; &lt;p&gt;Like the article I wrote about&lt;a href="https://developers.redhat.com/blog/2020/09/24/new-c-features-in-gcc-10"&gt; GCC 10&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/04/25/new-c-features-gcc-12"&gt;GCC 12&lt;/a&gt;, this article describes only new features implemented in the &lt;a href="https://developers.redhat.com/topics/c"&gt;C++&lt;/a&gt; front end; it does not discuss developments in the C++ language itself. Interesting changes in the standard C++ library that comes with GCC 13 are described in a separate blog post: &lt;a href="https://developers.redhat.com/articles/2023/04/19/new-c-features-gcc-13"&gt;New C features in GCC 13&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The default dialect in GCC 13 is &lt;code&gt;-std=gnu++17&lt;/code&gt;.  You can use the &lt;code&gt;-std=c++23&lt;/code&gt; or &lt;code&gt;-std=gnu++23&lt;/code&gt; command-line options to enable C++23 features, and similarly for C++20 and others. Note that C++20 and C++23 features are still experimental in GCC 13.&lt;/p&gt; &lt;h2&gt;C++23 features&lt;/h2&gt; &lt;p&gt;This section describes the following new C++23 features:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;static_assert (false)&lt;/code&gt; in templates&lt;/li&gt; &lt;li&gt;De-deprecating volatile compound operations&lt;/li&gt; &lt;li&gt;Relaxing &lt;code&gt;constexpr&lt;/code&gt; restrictions&lt;/li&gt; &lt;li&gt;Static operators&lt;/li&gt; &lt;li&gt;Extended floating-point types&lt;/li&gt; &lt;li&gt;Simpler implicit move&lt;/li&gt; &lt;li&gt;Equality operator fix&lt;/li&gt; &lt;li&gt;Portable assumptions&lt;/li&gt; &lt;li&gt;&lt;code&gt;char8_t &lt;/code&gt;compatibility fix&lt;/li&gt; &lt;li&gt;Labels at the end of compound statements&lt;/li&gt; &lt;li&gt;Traits to detect reference binding to temporary&lt;/li&gt; &lt;li&gt;C++ Contracts&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;static_assert (false) in templates&lt;/h3&gt; &lt;p&gt;GCC 13 resolves &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2593r0.html"&gt;P2593R0&lt;/a&gt; / &lt;a href="https://cplusplus.github.io/CWG/issues/2518.html"&gt;CWG 2518&lt;/a&gt;. The consequence is that a failing &lt;code&gt;static_assert&lt;/code&gt; is only ill-formed at instantiation time. In other words, this program compiles without errors in all C++ modes with GCC 13:&lt;/p&gt; &lt;pre&gt; template&lt;typename&gt; void f() { static_assert (false, ""); } &lt;/pre&gt; &lt;p&gt;because &lt;code&gt;static_assert (false)&lt;/code&gt; in uninstantiated templates is now accepted. (GCC 12 rejected the example above.)&lt;/p&gt; &lt;h3&gt;De-deprecating volatile compound operations&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2327r1.pdf"&gt;P2327R1&lt;/a&gt; partially reverts C++20 &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1152r4.html"&gt;P1152R4&lt;/a&gt;, which deprecated many uses of &lt;code&gt;volatile&lt;/code&gt;. As a consequence, bit-wise operations on volatile operands no longer warn:&lt;/p&gt; &lt;pre&gt; volatile int vi; int i; void g() { vi ^= i; // no -Wvolatile warning vi |= i; // no -Wvolatile warning vi &amp;= i; // no -Wvolatile warning }&lt;/pre&gt; &lt;p&gt;The change was backported to GCC 12 and 11 as well, so those versions also don’t warn for the test case above. A related defect report, &lt;a href="https://cplusplus.github.io/CWG/issues/2654.html"&gt;CWG 2654&lt;/a&gt;, was recently approved, meaning that the rest of the compound assignment operators were un-deprecated as well. GCC 13 already implements this defect report, so the warning doesn’t trigger for other compound operations such as &lt;code&gt;+=&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Relaxing constexpr restrictions&lt;/h3&gt; &lt;p&gt;It’s become customary to relax restrictions about the usage of the &lt;code&gt;constexpr&lt;/code&gt; keyword since its introduction in C++11. C++23 doesn’t break this habit. In C++23 (but not earlier modes), &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2647r1.html"&gt;P2647R1&lt;/a&gt; allows using &lt;code&gt;static constexpr&lt;/code&gt; variables in &lt;code&gt;constexpr&lt;/code&gt; functions:&lt;/p&gt; &lt;pre&gt; constexpr char test () { static constexpr char c[] = "Hello World"; // OK in C++23 return c[1]; } static_assert (test () == 'e'); &lt;/pre&gt; &lt;p&gt;In a similar vein, &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2448r2.html"&gt;P2448R2&lt;/a&gt; brings further &lt;code&gt;constexpr&lt;/code&gt; relaxation: in C++23, a &lt;code&gt;constexpr&lt;/code&gt; function’s return type or the type of its parameter does not have to be a literal type anymore, and, perhaps more importantly, a &lt;code&gt;constexpr&lt;/code&gt; function does not necessarily need to satisfy the requirement of a core constant expression (but actually calling such a function will result in a compile-time error). The intent is to allow functions to be marked &lt;code&gt;constexpr&lt;/code&gt; that will later become usable in a constant expression, once other functions that they call become &lt;code&gt;constexpr&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;GCC offers a new option, &lt;code&gt;-Winvalid-constexpr&lt;/code&gt;, to get a diagnostic when a function could not be invoked in a &lt;code&gt;constexpr&lt;/code&gt; context yet even in C++23 mode.&lt;/p&gt; &lt;pre&gt; void f (int&amp; i); constexpr void g (int&amp; i) { f(i); // warns by default in C++20, in C++23 only with -Winvalid-constexpr }&lt;/pre&gt; &lt;h3&gt;Static operators&lt;/h3&gt; &lt;p&gt;GCC 13 implements both &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1169r4.html"&gt;P1169R4&lt;/a&gt; - &lt;code&gt;static operator()&lt;/code&gt; and &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2589r1.pdf"&gt;P2589R1&lt;/a&gt; - &lt;code&gt;static operator[]&lt;/code&gt;. As the names suggest, these proposals allow the programmer to create a static function call operator and a static subscript operator. Every non-static member function needs to pass the invisible &lt;code&gt;this&lt;/code&gt; pointer, which causes additional overhead when such a function is invoked. A static member function avoids the overhead because it doesn’t get the implicit object parameter.&lt;/p&gt; &lt;pre&gt; struct S { static constexpr bool operator() (int x, int y) { return x &lt; y; } }; constexpr S s; static_assert (s (1, 2)); void g() { S::operator()(1, 2); // OK in C++23 } &lt;/pre&gt; &lt;p&gt;Similarly, &lt;code&gt;operator[]&lt;/code&gt; can be marked &lt;code&gt;static&lt;/code&gt; as well:&lt;/p&gt; &lt;pre&gt; struct S { S() {} static int&amp; operator[]() { return mem[0]; } static int mem[64]; }; void g() { S s; s[]++; }&lt;/pre&gt; &lt;p&gt;Interested readers can read more about the motivation for this change &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1169r4.html#motivation"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Extended floating-point types&lt;/h3&gt; &lt;p&gt;Since GCC 13 implements &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1467r9.html"&gt;P1467R9&lt;/a&gt;, users can now use types such as &lt;code&gt;std::float16_t&lt;/code&gt; and similar:&lt;/p&gt; &lt;pre&gt; #include &lt;stdfloat&gt; int main () { std::float16_t f16 = 1.0f16; std::float32_t f32 = 2.0f32; std::float64_t f64 = 3.0f64; std::float128_t f128 = 4.0f128; }&lt;/pre&gt; &lt;p&gt;These types are becoming popular in fields like machine learning, computer graphics, weather modelers and similar, where it’s typically required to perform a huge amount of computations, but what precision is important depends on the particular use case. &lt;code&gt;std::float32_t&lt;/code&gt; and &lt;code&gt;std::float64_t&lt;/code&gt; are available on almost every architecture; &lt;code&gt;std::float16_t&lt;/code&gt; is currently available on x86_64, aarch64, and a few other architectures; and &lt;code&gt;std::float128_t&lt;/code&gt; is available on architectures that support the &lt;code&gt;__float128&lt;/code&gt;/&lt;code&gt;_Float128&lt;/code&gt; types.&lt;/p&gt; &lt;p&gt;On x86_64 and aarch64, &lt;code&gt;std::bfloat16&lt;/code&gt; is supported as well (the support comes with software emulation as well):&lt;/p&gt; &lt;pre&gt; std::bfloat16_t x = 1.0bf16;&lt;/pre&gt; &lt;h3&gt;Simpler implicit move&lt;/h3&gt; &lt;p&gt;The rules mandating implicit move unfortunately keep changing; over the years we have had at least &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0527r1.html"&gt;P0527R1&lt;/a&gt;, &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1155r3.html"&gt;P1155R3&lt;/a&gt;, and &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1825r0.html"&gt;P1825R0&lt;/a&gt;. C++23 brought &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2266r3.html"&gt;P2266R3&lt;/a&gt;, attempting to simplify the rules. For example, the cumbersome maybe-double overload resolution rule was removed. Additionally, P2266 enabled the implicit move even for functions that return references, e.g.:&lt;/p&gt; &lt;pre&gt; struct X { }; X&amp;&amp; foo (X&amp;&amp; x) { return x; } &lt;/pre&gt; &lt;p&gt;As a consequence, previously valid code may not compile anymore in C++23:&lt;/p&gt; &lt;pre&gt; int&amp; g(int&amp;&amp; x) { return x; } &lt;/pre&gt; &lt;p&gt;Because &lt;code&gt;x&lt;/code&gt; is treated as an rvalue in C++23, and it’s not allowed to bind a non-const lvalue reference to an rvalue. For more information, please see the &lt;a href="https://gcc.gnu.org/gcc-13/porting_to.html"&gt;Porting To&lt;/a&gt; documentation.&lt;/p&gt; &lt;h3&gt;Equality operator fix&lt;/h3&gt; &lt;p&gt;As a &lt;a href="https://developers.redhat.com/articles/2022/03/29/c-standardization-core-language-progress-2021#what_s_in_the_pipeline_for_c__23_"&gt;previous blog&lt;/a&gt; explained, the implicit reversing of &lt;code&gt;operator==&lt;/code&gt; made some valid C++17 code ill-formed in C++20, for instance when a class defines comparison operators that are accidentally asymmetric:&lt;/p&gt; &lt;pre&gt; struct S { bool operator==(const S&amp;) { return true; } // mistakenly non-const bool operator!=(const S&amp;) { return false; } // mistakenly non-const }; bool b = S{} != S{}; // well-formed in C++17, ambiguous in C++20 &lt;/pre&gt; &lt;p&gt;The problem was that the asymmetric &lt;code&gt;operator==&lt;/code&gt; was compared to itself in reverse. GCC implemented a tiebreaker to make the test case above work even in C++20, but the C++ committee resolved the issue in a different way: &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2468r2.html"&gt;P2468R2&lt;/a&gt; says that if there is an &lt;code&gt;operator!=&lt;/code&gt; with the same parameter types as the &lt;code&gt;operator==&lt;/code&gt;, the reversed form of the &lt;code&gt;operator==&lt;/code&gt; is ignored. GCC 13 implements the standardized approach.&lt;/p&gt; &lt;h3&gt;Portable assumptions&lt;/h3&gt; &lt;p&gt;GCC 13 gained support for &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p1774r8.pdf"&gt;P1774R8&lt;/a&gt;, a paper describing how a programmer can use the construct &lt;code&gt;[[assume(expr)]]&lt;/code&gt; to allow the compiler to assume that &lt;code&gt;expr&lt;/code&gt; is true and optimize the code accordingly. Most compilers already provide a non-standard way to achieve this. For example, GCC supports the &lt;code&gt;__builtin_unreachable&lt;/code&gt; built-in function. When used correctly, the resulting code may be both smaller and faster than a version without the &lt;code&gt;[[assume]]&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Consider the following (silly) function:&lt;/p&gt; &lt;pre&gt; int foo (int x, int y) { [[assume (x &gt;= y)]]; if (x == y) return 0; else if (x &gt; y) return 1; else return -1; } &lt;/pre&gt; &lt;p&gt;And the difference in the (x86) output assembly without/with the &lt;code&gt;assume&lt;/code&gt; attribute:&lt;/p&gt; &lt;pre&gt; @@ -8,11 +8,7 @@ _Z3fooii: .cfi_startproc xorl %eax, %eax cmpl %esi, %edi - je .L1 - setg %al - movzbl %al, %eax - leal -1(%rax,%rax), %eax -.L1: + setne %al ret .cfi_endproc .LFE0: &lt;/pre&gt; &lt;p&gt;With the attribute, in this case, all the compiler needs to do is to check if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are equal, because it knows it can assume that &lt;code&gt;x&lt;/code&gt; cannot be less than &lt;code&gt;y&lt;/code&gt;; this results in better output code. Such an optimization is typically the result of the Value Range Propagation optimization taking place.&lt;/p&gt; &lt;p&gt;Note, however, that if the assumption is violated, the code triggers undefined behavior and the compiler is then free to do absolutely anything, so the attribute should be used sparingly and with great care. Also note that the compiler is free to ignore the attribute altogether.&lt;/p&gt; &lt;h3&gt;char8_t compatibility fix&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0482r6.html"&gt;P0482R6&lt;/a&gt;, which added the &lt;code&gt;char8_t&lt;/code&gt; type, didn’t permit&lt;/p&gt; &lt;pre&gt; const char arr[] = u8"hi";&lt;/pre&gt; &lt;p&gt;But that caused problems in practice, so the example above is allowed under &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2513r4.html"&gt;P2513R4&lt;/a&gt;, which GCC 13 implements.&lt;/p&gt; &lt;h3&gt;Labels at the end of compound statements&lt;/h3&gt; &lt;p&gt;GCC 13 implements proposal &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2324r2.pdf"&gt;P2324R2&lt;/a&gt;. C2X (the next major C language standard revision) has started allowing labels at the end of a compound statement (which is, for example, before a function’s final &lt;code&gt;}&lt;/code&gt;) without a following &lt;code&gt;;&lt;/code&gt;. The C2X proposal was implemented in GCC 11. To minimize differences between C and C++ in this regard, C++ followed suit:&lt;/p&gt; &lt;pre&gt; void p2324 () { first: int x; second: x = 1; last: // no error in C++23 }&lt;/pre&gt; &lt;h3&gt;Traits to detect reference binding to temporary&lt;/h3&gt; &lt;p&gt;GCC 13 supports &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2255r2.html"&gt;P2255R2&lt;/a&gt;, which adds two new type traits to detect reference binding to a temporary. They can be used to detect code like&lt;/p&gt; &lt;pre&gt; std::pair&lt;const std::string&amp;, int&gt; p("meow", 1);&lt;/pre&gt; &lt;p&gt;which is incorrect because it always creates a dangling reference, because the &lt;code&gt;std::string&lt;/code&gt; temporary is created inside the selected constructor of &lt;code&gt;std::pair&lt;/code&gt;, and not outside it. These traits are called &lt;code&gt;std::reference_constructs_from_temporary&lt;/code&gt; and &lt;code&gt;std::reference_converts_from_temporary&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We have made use of these new traits in the standard C++ library to detect buggy code. For example, certain wrong uses of &lt;code&gt;std::function&lt;/code&gt;, &lt;code&gt;std::pair&lt;/code&gt;, and &lt;code&gt;std::make_from_tuple&lt;/code&gt; are now caught and an error is issued.&lt;/p&gt; &lt;h3&gt;Contracts&lt;/h3&gt; &lt;p&gt;Even though C++ Contracts are not in the C++ standard yet (although they briefly were in &lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/n4820.pdf"&gt;N4820&lt;/a&gt;—see &lt;em&gt;Contract Attributes&lt;/em&gt;), GCC 13 implements a draft of C++ Contracts. This feature is highly experimental and has to be enabled by the &lt;code&gt;-fcontracts&lt;/code&gt; option. (It also requires that the program is linked with &lt;code&gt;-lstdc++exp&lt;/code&gt;.) Here’s an example of the &lt;code&gt;pre&lt;/code&gt; feature:&lt;/p&gt; &lt;pre&gt; void f (int x) [[ pre: x &gt;= 0 ]] // line 3 { } int main () { f (1); // OK f (0); // OK f (-1); // oops } &lt;/pre&gt; &lt;p&gt;This program, when compiled with &lt;code&gt;-fcontracts -std=c++20&lt;/code&gt; and run, will output the following:&lt;/p&gt; &lt;pre&gt; $ ./contracts_demo contract violation in function f at g.C:3: x &gt;= 0 terminate called without an active exception Aborted (core dumped)&lt;/pre&gt; &lt;h2&gt;Defect report resolutions&lt;/h2&gt; &lt;p&gt;A number of defect reports were resolved in GCC 13. A few examples follow.&lt;/p&gt; &lt;h3&gt;operator[] and default arguments&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2128r6.pdf"&gt;P2128R6&lt;/a&gt;, which added support for the multidimensional subscript operator, meant to allow default arguments, but accidentally did not. This was fixed in &lt;a href="https://cplusplus.github.io/CWG/issues/2507.html"&gt;CWG 2507&lt;/a&gt;, and the following example compiles in C++23 mode:&lt;/p&gt; &lt;pre&gt; struct A { void operator[](int, int = 42); };&lt;/pre&gt; &lt;h3&gt;attributes on concepts&lt;/h3&gt; &lt;p&gt;Since &lt;a href="https://cplusplus.github.io/CWG/issues/2428.html"&gt;CWG 2428&lt;/a&gt;, it’s permitted to have attributes on concepts:&lt;/p&gt; &lt;pre&gt; template&lt;typename T&gt; concept C [[deprecated]] = true;&lt;/pre&gt; &lt;h3&gt;consteval in default arguments&lt;/h3&gt; &lt;p&gt;Spurred by problems revolving around the usage of &lt;code&gt;source_location::current&lt;/code&gt;, &lt;a href="https://cplusplus.github.io/CWG/issues/2631.html"&gt;CWG 2631&lt;/a&gt; clarifies that immediate function calls in default arguments are not evaluated until the default argument is used (rather than being evaluated where they are defined, as part of the semantic constraints checking).&lt;/p&gt; &lt;h2&gt;Additional updates&lt;/h2&gt; &lt;p&gt;This section describes other enhancements in GCC 13&lt;/p&gt; &lt;h3&gt;Concepts fixes&lt;/h3&gt; &lt;p&gt;The C++ Concepts code has gotten a lot of bug fixes and a number of loose ends were tied up.&lt;/p&gt; &lt;p&gt;If you had issues with GCC 12 on concepts-heavy code, chances are GCC 13 will do a much better job.&lt;/p&gt; &lt;h3&gt;Mixing of GNU and standard attributes&lt;/h3&gt; &lt;p&gt;GCC 13 allows mixing GNU and standard (of the &lt;code&gt;[[ ]]&lt;/code&gt; form) attributes. Not allowing it caused problems with code, like:&lt;/p&gt; &lt;pre&gt; struct __attribute__ ((may_alias)) alignas (2) struct S { };&lt;/pre&gt; &lt;p&gt;or:&lt;/p&gt; &lt;pre&gt; #define EXPORT __attribute__((visibility("default"))) struct [[nodiscard]] EXPORT F { };&lt;/pre&gt; &lt;h3&gt;Reduced memory usage and compile time&lt;/h3&gt; &lt;p&gt;In GCC 13, we implemented various optimizations that reduce memory usage of the compiler. For example, specialization of nested templated classes has been optimized by reducing the number of unnecessary substitutions. Details can be found &lt;a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=cb7fd1ea85feea7ef65328330fc2577a95e99400"&gt;here&lt;/a&gt;.  Another optimization was to reduce compile time by improving hashing of typenames.&lt;/p&gt; &lt;p&gt;To improve compile times, the compiler in GCC 13 provides new built-ins which the standard C++ library can use. It is generally faster to use a compiler built-in rather than instantiating a (potentially large) number of class templates and similar. For instance, GCC 13 added &lt;code&gt;__is_convertible&lt;/code&gt; and &lt;code&gt;__is_nothrow_convertible&lt;/code&gt;, as well as &lt;code&gt;__remove_cv&lt;/code&gt;, &lt;code&gt;__remove_reference&lt;/code&gt; and &lt;code&gt;__remove_cvref&lt;/code&gt; built-ins.&lt;/p&gt; &lt;p&gt;Another optimization was to reduce the number of temporaries when initializing an array of &lt;code&gt;std::string&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;-nostdlib++&lt;/h3&gt; &lt;p&gt;The C++ front end now understands the new option &lt;code&gt;-nostdlib++&lt;/code&gt;, which enables linking without implicitly linking in the C++ standard library.&lt;/p&gt; &lt;h3&gt;-fconcepts option cleaned up&lt;/h3&gt; &lt;p&gt;Previously, &lt;code&gt;-fconcepts&lt;/code&gt; in C++17 meant the same thing as &lt;code&gt;-fconcepts-ts&lt;/code&gt; (enabling Concepts Technical Specification which allows constructs not allowed by the standard) in C++20. This oddity was cleaned up and now &lt;code&gt;-fconcepts&lt;/code&gt; no longer implies &lt;code&gt;-fconcepts-ts&lt;/code&gt; prior to C++20. (We recommend using &lt;code&gt;-std=c++20&lt;/code&gt; if your code uses C++ Concepts.)&lt;/p&gt; &lt;h2&gt;New and improved warnings&lt;/h2&gt; &lt;p&gt;GCC's set of warning options have been enhanced in GCC 13.&lt;/p&gt; &lt;h3&gt;-Wparentheses and operator=&lt;/h3&gt; &lt;p&gt;&lt;code&gt;-Wparentheses&lt;/code&gt; in GCC 13 warns when an &lt;code&gt;operator=&lt;/code&gt; is used as a truth condition:&lt;/p&gt; &lt;pre&gt; struct A { A&amp; operator=(int); operator bool(); }; void f (A a) { if (a = 0); // warn }&lt;/pre&gt; &lt;h3&gt;Various std::move warnings improved&lt;/h3&gt; &lt;p&gt;GCC 12 already had a warning which warns about pessimizing uses of &lt;code&gt;std::move&lt;/code&gt; in a return statement. (See a related &lt;a href="https://developers.redhat.com/blog/2019/04/12/understanding-when-not-to-stdmove-in-c"&gt;blog post&lt;/a&gt; for more on this.) However, the warning didn’t warn about returning a class &lt;em&gt;prvalues&lt;/em&gt;, where a &lt;code&gt;std::move&lt;/code&gt; also prevents the Return Value Optimization. This has been fixed, and the warning now warns about the &lt;code&gt;std::move&lt;/code&gt; in:&lt;/p&gt; &lt;pre&gt; T fn() { T t; return std::move (T{}); } &lt;/pre&gt; &lt;p&gt;as well. Moreover, &lt;code&gt;-Wpessimizing-move&lt;/code&gt; warns in more contexts. For example:&lt;/p&gt; &lt;pre&gt; T t = std::move(T()); T t(std::move(T())); T t{std::move(T())}; T t = {std::move(T())}; void foo (T); foo (std::move(T()));&lt;/pre&gt; &lt;p&gt;A related warning, &lt;code&gt;-Wredundant-move&lt;/code&gt;, was extended to warn when the user is moving a &lt;code&gt;const&lt;/code&gt; object as in:&lt;/p&gt; &lt;pre&gt; struct T { }; T f(const T&amp; t) { return std::move(t); } &lt;/pre&gt; &lt;p&gt;where the &lt;code&gt;std::move&lt;/code&gt; is redundant, because &lt;code&gt;T&lt;/code&gt; does not have a &lt;code&gt;T(const T&amp;&amp;)&lt;/code&gt; constructor (which is very unlikely). Even with the &lt;code&gt;std::move&lt;/code&gt;, &lt;code&gt;T(T&amp;&amp;)&lt;/code&gt; would not be used because it would mean losing the &lt;code&gt;const&lt;/code&gt; qualifier. Instead, &lt;code&gt;T(const T&amp;)&lt;/code&gt; will be called.&lt;/p&gt; &lt;h3&gt;New warning: -Wself-move&lt;/h3&gt; &lt;p&gt;Relatedly to the previous paragraph, GCC 13 gained a new warning, which warns about useless “self” moves as in the example below.&lt;/p&gt; &lt;pre&gt; int x = 42; x = std::move (x);&lt;/pre&gt; &lt;h3&gt;New warning: -Wdangling-reference&lt;/h3&gt; &lt;p&gt;GCC 13 implements a fairly bold new warning to detect bugs in the source code when a reference is bound to a temporary whose lifetime has ended, which is undefined behavior. The canonical example is&lt;/p&gt; &lt;pre&gt; int n = 1; const int&amp; r = std::max(n-1, n+1); // r is dangling &lt;/pre&gt; &lt;p&gt;where both temporaries (that had been created for &lt;code&gt;n-1&lt;/code&gt; and &lt;code&gt;n+1&lt;/code&gt;) were destroyed at the end of the full expression. This warning (enabled by &lt;code&gt;-Wall&lt;/code&gt;) detects this problem. It works by employing a heuristic which checks if a reference is initialized by a function call that returns a reference and at least one parameter of the called function is a reference that is bound to a temporary.&lt;/p&gt; &lt;p&gt;Because the compiler does not check the definition of the called function (and often the definition isn’t even visible), the warning can be fooled, although in practice it doesn’t happen very often. However, there are functions like &lt;code&gt;std::use_facet&lt;/code&gt; that take and return a reference but don’t return one of its arguments. In such cases, we suggest suppressing the warning by using a &lt;code&gt;#pragma&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; #pragma GCC diagnostic push #pragma GCC diagnostic ignored "-Wdangling-reference" const T&amp; foo (const T&amp;) { ... } #pragma GCC diagnostic pop&lt;/pre&gt; &lt;p&gt;Subsequently, the warning was extended to also warn about a common “footgun” concerning &lt;code&gt;std::minmax&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; auto v = std::minmax(1, 2);&lt;/pre&gt; &lt;p&gt;which, perhaps not obviously, also contains a dangling reference: the selected &lt;code&gt;std::minmax&lt;/code&gt; overload returns &lt;code&gt;std::pair&lt;const int&amp;, const int&amp;&gt;&lt;/code&gt; where the two &lt;code&gt;const int&lt;/code&gt; references are bound to temporaries. Since its inception, the warning has been tweaked a number of times. For instance, we adjusted it to ignore reference-like classes, because those tended to provoke false positives.&lt;/p&gt; &lt;h3&gt;New warning: -Wxor-used-as-pow&lt;/h3&gt; &lt;p&gt;This warning warns about suspicious uses of the exclusive OR operator &lt;code&gt;^&lt;/code&gt;. For instance, when the user writes &lt;code&gt;2^8&lt;/code&gt;, it’s likely that they actually meant &lt;code&gt;1 &lt;&lt; 8&lt;/code&gt;. To reduce the number of false positives and make the warning useful in practice, it only warns when the first operand is the decimal constant 2 or 10.&lt;/p&gt; &lt;h3&gt;New option: -Wchanges-meaning&lt;/h3&gt; &lt;p&gt;In C++, a name in a class must have the same meaning in the complete scope of the class.  To that effect, GCC 12 emits an &lt;code&gt;-fpermissive&lt;/code&gt; error for&lt;/p&gt; &lt;pre&gt; struct A {}; struct B { A a; struct A { }; }; // error, A changes meaning &lt;/pre&gt; &lt;p&gt;In GCC 13, it is possible to disable this particular diagnostic by using the new command-line option &lt;code&gt;-Wchanges-meaning&lt;/code&gt;. Having a dedicated option to control this diagnostic is useful because other compilers aren’t as consistent in detecting this invalid code.&lt;/p&gt; &lt;h3&gt;Color function names in diagnostic&lt;/h3&gt; &lt;p&gt;This change can be best demonstrated with a screenshot (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/c-plus-plus-color-function.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/c-plus-plus-color-function.png?itok=uUTLrP6r" width="600" height="380" alt="Function names appear in color in GCC 13." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: C function names formatted in color.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;As usual, I'd like to thank my coworkers at Red Hat who made the GNU C++ compiler so much better, notably Jason Merrill, Jakub Jelinek, Patrick Palka, and Jonathan Wakely.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/21/new-c-features-gcc-13" title="New C++ features in GCC 13"&gt;New C++ features in GCC 13&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Marek Polacek</dc:creator><dc:date>2023-06-21T07:00:00Z</dc:date></entry><entry><title type="html">Designing Quarkus Front-Ends with Vaadin made easy</title><link rel="alternate" href="https://www.mastertheboss.com/soa-cloud/quarkus/designing-quarkus-front-ends-with-vaadin-made-easy/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/soa-cloud/quarkus/designing-quarkus-front-ends-with-vaadin-made-easy/</id><updated>2023-06-20T08:26:55Z</updated><content type="html">Vaadin Flow provides a comprehensive set of UI components and tools for creating rich and interactive user interfaces, while Quarkus offers a lightweight and efficient Java framework for developing cloud-native applications. In this article, we will explore how to combine the strengths of Vaadin and Quarkus to build web applications with ease. What is Vaadin? ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Debugging in GDB: Create custom stack winders</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" /><author><name>Andrew Burgess</name></author><id>1b158985-49f8-4ef2-8f7a-afa95cad693f</id><updated>2023-06-19T07:00:00Z</updated><published>2023-06-19T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will walk through the process of creating a custom stack unwinder for the GNU Project Debugger (GDB) using GDB's &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; API. We'll first explore when writing such an unwinder might be necessary, then create a small example application that demonstrates a need for a custom unwinder before finally writing a custom unwinder for our application inside the debugger.&lt;/p&gt; &lt;p&gt;By the end of this tutorial, you'll be able to use our custom stack unwinder to allow GDB to create a full backtrace for our application.&lt;/p&gt; &lt;h2&gt;What is an unwinder?&lt;/h2&gt; &lt;p&gt;An unwinder is how GDB figures out the call stack of an inferior, for example, GDB's &lt;code&gt;backtrace&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;Breakpoint 1, woof () at stack.c:4 4 return 0; (gdb) backtrace #0 woof () at stack.c:4 #1 0x000000000040111f in bar () at stack.c:10 #2 0x000000000040112f in foo () at stack.c:16 #3 0x000000000040113f in main () at stack.c:22 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Figuring out frame #0 is easy; the current program counter (&lt;code&gt;$pc&lt;/code&gt;) value tells GDB which function the inferior is currently in. But to figure out the other frames, GDB needs to read information from the inferior's registers and memory. The unwinder is the component of GDB that performs this task.&lt;/p&gt; &lt;p&gt;Having an understanding of the inferior's frames isn't just used for displaying the backtrace, though; commands like &lt;code&gt;next&lt;/code&gt; and &lt;code&gt;finish&lt;/code&gt; also need an accurate understanding of the stack frames in order to function properly.&lt;/p&gt; &lt;p&gt;Any time GDB needs information about a frame beyond #0, an unwinder will have been used.&lt;/p&gt; &lt;h2&gt;What is a custom unwinder?&lt;/h2&gt; &lt;p&gt;GDB already has multiple built-in unwinders for all the major architectures GDB supports. By far, the most common unwinder will be the DWARF unwinder, which reads the DWARF debug information and uses it to unwind the stack for GDB.&lt;/p&gt; &lt;p&gt;But not all functions are compiled with debug information. When GDB finds a function without DWARF debug information, it falls back to a built-in prologue analysis unwinder.&lt;/p&gt; &lt;p&gt;The prologue analysis unwinder disassembles the instructions at the start of a function and uses this information, combined with an understanding of the architecture's ABI, to provide unwind information. For many functions, the prologue analysis unwinder will do a reasonable job. Still, there's a limit to how smart the prologue analysis unwinder can be, and GDB can never expect to handle every function this way.&lt;/p&gt; &lt;p&gt;And this is where the Python unwinder API comes in. Using this API, it is possible to write Python code that will be loaded into GDB. This code can then "claim" frames for which GDB is otherwise unable to unwind correctly, and the Python code can instead be used to provide the unwind information to GDB.&lt;/p&gt; &lt;h2&gt;Building an example use case&lt;/h2&gt; &lt;p&gt;In most well-written applications, very few functions will need the support of a custom unwinder. The sort of functions that GDB will struggle with are those that do unexpected things with the underlying machine state; for example, functions that manipulate the stack in unexpected ways are likely to confuse GDB.&lt;/p&gt; &lt;p&gt;The example application we're going to write does just that: it allocates a second stack and uses a small assembler function to switch to, and run a function on, the new stack.&lt;/p&gt; &lt;p&gt;GDB will have no problem unwinding the standard C frames, but the assembler function, which changes the stack, is going to confuse GDB, and initially, we will be unable to obtain a &lt;code&gt;backtrace&lt;/code&gt; through this function.&lt;/p&gt; &lt;p&gt;Of course, writing in assembly language means this application will only work for one architecture, in this case, x86-64, and the unwinder we eventually write will also be tied to this one architecture. This is perfectly normal; unwinders are dealing with machine registers, so it is expected that an unwinder will only apply to a single architecture.&lt;/p&gt; &lt;p&gt;The demonstration application is split into two files, first, we have &lt;code&gt;demo.c&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;stdio.h&gt; #include &lt;sys/mman.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; /* This function is in our assembly file. */ extern void run_on_new_stack (void *stack, void (*) (void)); /* Return pointer to the top of a new stack. */ static void * allocate_new_stack (void) { int pagesz = getpagesize (); void *ptr = mmap (NULL, pagesz, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); if (ptr == MAP_FAILED) abort (); return ptr + pagesz; } /* A function to run on the alternative stack. */ static void func (void) { printf ("Hello world\n"); } /* Allocate a new stack. Run a function on the new stack. */ int main (void) { void *new_stack = allocate_new_stack (); run_on_new_stack (new_stack, func); return 0; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then we have &lt;code&gt;runon.S&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; .global run_on_new_stack run_on_new_stack: /* Incoming arguments: %rdi - top of new stack pointer, %rsi - function to call. Store previous %rbp and %rsp to the new stack. Set %rbp and $rsp to point to the new stack. Call the function in %rsi. */ mov %rbp, -8(%rdi) mov %rsp, -16(%rdi) add $-16, %rdi mov %rdi, %rbp mov %rdi, %rsp callq *%rsi movq 0(%rbp), %rsp movq 8(%rbp), %rbp ret .size run_on_new_stack, . - run_on_new_stack .type run_on_new_stack, @function &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, compile the application like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;gcc -g3 -O0 -Wall -Werror -o demo demo.c runon.S&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now let's see how GDB handles stack unwinding without any additional support. For this, I'm using GDB 13.1:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad68 in ?? () #3 0x00007fffffffad80 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see, GDB can unwind from &lt;code&gt;func&lt;/code&gt; just fine; after all, that is a "normal" function compiled with debug information. But GDB is unable to figure out how to unwind from &lt;code&gt;run_on_new_stack&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;What our application is actually doing&lt;/h3&gt; &lt;p&gt;Before we can write a custom unwinder in Python, we need to make sure we fully understand what the demonstration application is actually doing.&lt;/p&gt; &lt;p&gt;We have three frames: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;run_on_new_stack&lt;/code&gt;, and &lt;code&gt;func&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, just before we call &lt;code&gt;run_on_new_stack&lt;/code&gt;, the application’s stack looks like Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_01_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_01_0.png?itok=qh8NGQuG" width="532" height="397" alt="Stack in main, just before run_on_new_stack is called." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Stack in main, just before run_on_new_stack is called.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The register &lt;code&gt;%rbp&lt;/code&gt;, sometimes known as the frame pointer, points to the top of the frame for &lt;code&gt;main&lt;/code&gt;, while &lt;code&gt;%rsp&lt;/code&gt;, otherwise known as the stack pointer, points to the last valid address of the frame for &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When we call from &lt;code&gt;main&lt;/code&gt; to &lt;code&gt;run_on_new_stack&lt;/code&gt;, the return address within &lt;code&gt;main&lt;/code&gt; is pushed onto the stack and &lt;code&gt;%rsp&lt;/code&gt; is updated. The stack now looks like Figure 2.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_02_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_02_0.png?itok=VAH8dv9U" width="532" height="454" alt="State of the stack upon entry to run_on_new_stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: State of the stack upon entry to run_on_new_stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, we also allocated a new stack, and this was passed through as the first function argument to &lt;code&gt;run_on_new_stack&lt;/code&gt;. As such, register &lt;code&gt;%rdi&lt;/code&gt; points at an address just above the new stack, like this (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_03_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_03_0.png?itok=MiI5PIb6" width="310" height="397" alt="Visualisation of the new, empty stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Visualisation of the new, empty stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Within &lt;code&gt;run_on_new_stack&lt;/code&gt; we switch over to the new stack. The return address within &lt;code&gt;main&lt;/code&gt; is left on the original stack, and the pointers (&lt;code&gt;%rbp&lt;/code&gt; and &lt;code&gt;%rsp&lt;/code&gt;) to the original stack are backed up on the new stack, and then updated to point at the new stack. We then call &lt;code&gt;func&lt;/code&gt;, which will push the return address within &lt;code&gt;run_on_new_stack&lt;/code&gt; onto the new stack. Once we are in &lt;code&gt;func&lt;/code&gt;, the state of the two stacks is now as shown in Figures 4 and 5.&lt;/p&gt; &lt;table border="0" cellpadding="1" cellspacing="1"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_04_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_04_0.png?itok=gstn156K" width="443" height="397" alt="Layout of the original stack once run_on_new_stack has switched to the new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Layout of the original stack once run_on_new_stack has switched to the new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_05_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_05_0.png?itok=lK6M13ca" width="532" height="454" alt="Layout of new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Layout of new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;When unwinding, GDB doesn't understand how to use the information on the new stack to find the original stack, and so the &lt;code&gt;backtrace&lt;/code&gt; is incomplete. This is the problem that our custom unwinder will solve for us.&lt;/p&gt; &lt;h3&gt;Starting our custom unwinder&lt;/h3&gt; &lt;p&gt;The custom unwinder will be written as a Python script in the file &lt;code&gt;runon-unwind.py&lt;/code&gt;, which we can then source in GDB to provide the extra functionality.&lt;/p&gt; &lt;p&gt;In GDB's Python API, an unwinder is an object that implements the &lt;code&gt;__call__&lt;/code&gt; method. GDB will call each unwinder object for every frame; the unwinder should return &lt;code&gt;None&lt;/code&gt; if the unwinder doesn't handle the frame or return a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object if the unwinder wishes to take responsibility for the frame.&lt;/p&gt; &lt;p&gt;Let's start by writing an empty unwinder that doesn't claim any frames:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last line of this file is responsible for registering the new unwinder with GDB. The first argument &lt;code&gt;None&lt;/code&gt; tells GDB to register this unwinder in the global scope, but it is also possible to register an unwinder for a specific object file or a specific program space. We'll not cover these cases in this tutorial, but the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;GDB documentation&lt;/a&gt; has more details.&lt;/p&gt; &lt;p&gt;The second argument to &lt;code&gt;register_unwinder&lt;/code&gt; is our new unwinder object. We'll discuss this more below.&lt;/p&gt; &lt;p&gt;The final argument &lt;code&gt;replace=True&lt;/code&gt; indicates that this new unwinder should replace any existing unwinder with the same name. This is useful when developing the unwinder as we can adjust our script and re-source it from GDB; the updated unwinder will then replace the existing one.&lt;/p&gt; &lt;p&gt;In our unwinder object &lt;code&gt;runto_unwinder&lt;/code&gt;, the constructor just calls the parent constructor and passes in a name for our unwinder. The name can be used within GDB to disable and enable the unwinder using the &lt;code&gt;disable unwinder&lt;/code&gt; and &lt;code&gt;enable unwinder&lt;/code&gt; commands, respectively. There is also &lt;code&gt;info unwinder&lt;/code&gt; which lists all the registered Python unwinders.&lt;/p&gt; &lt;p&gt;Our unwinder object also implements the required &lt;code&gt;__call__&lt;/code&gt; method. This method is passed a &lt;code&gt;gdb.PendingFrame&lt;/code&gt; object in &lt;code&gt;pending_frame&lt;/code&gt;. This pending frame describes the frame that is searching for an unwinder. We must examine this object and decide whether this unwinder applies to this pending frame. By returning &lt;code&gt;None&lt;/code&gt;, our unwinder is currently telling GDB that we don't wish to claim &lt;code&gt;pending_frame&lt;/code&gt;, our unwinder as it currently stands will not claim any frames, but we can start to address that next.&lt;/p&gt; &lt;h3&gt;Identifying frames to claim&lt;/h3&gt; &lt;p&gt;The first task our new unwinder needs to do is to decide which frame, or frames, should be claimed and which should not be claimed. Any frames not claimed by our unwinder will be offered to any other registered unwinders and will then be offered to GDB's built-in unwinders.&lt;/p&gt; &lt;p&gt;The easiest way to decide if we should claim a frame or not is to compare the program-counter address within the frame to the address range of the function we're claiming for—in this case, &lt;code&gt;run_on_new_stack&lt;/code&gt;. We can easily find the program-counter address for the frame by reading the &lt;code&gt;$pc&lt;/code&gt; register. This is done using the &lt;code&gt;read_register&lt;/code&gt; method of the &lt;code&gt;gdb.PendingFrame&lt;/code&gt; class.&lt;/p&gt; &lt;p&gt;Having read &lt;code&gt;$pc&lt;/code&gt;, we need an address range to compare against. For that, we will make use of GDB's disassembler. We will disassemble &lt;code&gt;run_on_new_stack&lt;/code&gt; and extract the address of each instruction. We can then use the first and last addresses as the lower and upper bounds that our unwinder should claim.&lt;/p&gt; &lt;p&gt;Update &lt;code&gt;runon-unwinder.py&lt;/code&gt; like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new &lt;code&gt;analyze&lt;/code&gt; function disassembles &lt;code&gt;run_on_new_stack&lt;/code&gt; and stores the address of each instruction in the global &lt;code&gt;_unwind_analysis&lt;/code&gt; list.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;runto_unwinder.__call__&lt;/code&gt; we initialize &lt;code&gt;_unwind_analysis&lt;/code&gt; by calling &lt;code&gt;analyze&lt;/code&gt; once. We read &lt;code&gt;$pc&lt;/code&gt; by calling &lt;code&gt;pending_frame.read_register&lt;/code&gt;, and then we compare &lt;code&gt;pc&lt;/code&gt; to the first and last addresses in &lt;code&gt;_unwind_analysis&lt;/code&gt;. If the frame's program-counter is outside of the accepted range, then we return &lt;code&gt;None&lt;/code&gt;; this indicates to GDB that we don't wish to claim this frame.&lt;/p&gt; &lt;p&gt;If the frame's program-counter is within the range of &lt;code&gt;run_on_new_stack&lt;/code&gt;, then we print a message, and, for now, also return &lt;code&gt;None&lt;/code&gt;—don't worry, though, we'll soon be doing more than returning &lt;code&gt;None&lt;/code&gt; here, but right now, let's test our code.&lt;/p&gt; &lt;p&gt;Using the same demonstration application as before, here's an example GDB session:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runto-unwind.py (gdb) backtrace Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt; #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad38 in ?? () #3 0x00007fffffffad50 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice the line: &lt;code&gt;Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt;&lt;/code&gt;. Don't worry if the addresses you see are different; what's important is that the message is printed—and printed just once. This indicates that our unwinder has identified a single frame it wishes to claim. The address from that line, &lt;code&gt;0x4011fb&lt;/code&gt;, matches the address from frame #1, the &lt;code&gt;run_on_new_stack&lt;/code&gt; frame; this shows that the correct frame was claimed.&lt;/p&gt; &lt;h3&gt;A detour into frame-ids&lt;/h3&gt; &lt;p&gt;The next step is to update the &lt;code&gt;__call__&lt;/code&gt; method to return a value that indicates the frame has been claimed by this unwinder. However, in order to claim the frame, we must provide a frame-id for the frame.&lt;/p&gt; &lt;p&gt;A frame-id is a unique identifier generated by the unwinder that must be unique for each stack frame but the same for every address within a particular invocation of a function.&lt;/p&gt; &lt;p&gt;Imagine the case where GDB is stepping through a function. After each step, GDB needs to recognize if it is still in the same frame or not. After each step, the unwinder will be used to identify the frame and generate the frame-id again. So long as the generated frame-id is always the same, GDB will understand it is still in the same frame.&lt;/p&gt; &lt;p&gt;Within GDB, frame-ids are a tuple of stack-pointer and code-pointer addresses. Often unwinders use the stack address at entry to the function (typically called the frame base address), and the program address for the function's first instruction.&lt;/p&gt; &lt;p&gt;Within GDB's Python API, a frame-id is represented by any object that has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes. These attributes should contain &lt;code&gt;gdb.Value&lt;/code&gt; objects representing their respective addresses.&lt;/p&gt; &lt;h3&gt;Creating a frame-ID and UnwindInfo object&lt;/h3&gt; &lt;p&gt;Now that we know about frame-ids, let's dive in and update our unwinder. We'll discuss these changes afterward. Update &lt;code&gt;runto-unwind.py&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout # the frame, no matter what $pc we stop at. We use the $sp # value for the previous frame (this was our $sp on frame # entry), and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Currently, GDB doesn't include any helper classes that can be used to represent a frame-id, so we need to define our own – &lt;code&gt;FrameID&lt;/code&gt;. The only requirements are that this class has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes.&lt;/p&gt; &lt;p&gt;Within the &lt;code&gt;__call__&lt;/code&gt; method we use the first address of &lt;code&gt;run_on_new_stack&lt;/code&gt; as the program-counter value for the frame-id. This is done with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; func_start = gdb.Value(_unwind_analysis[0])&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the stack-pointer address of the frame-id, we need to be smarter. When we first enter &lt;code&gt;run_on_new_stack&lt;/code&gt;, the previous stack-pointer value is still present in &lt;code&gt;%rsp&lt;/code&gt;, but within &lt;code&gt;run_on_new_stack&lt;/code&gt;, the &lt;code&gt;%rsp&lt;/code&gt; register is stored to the new stack and a new value loaded into &lt;code&gt;%rsp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To handle these two cases, we use the following block of code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We choose between the two possible paths based on the current location within the function. The addresses &lt;code&gt;_unwind_analysis[5]&lt;/code&gt; and &lt;code&gt;_unwind_analysis[6]&lt;/code&gt; were chosen by reviewing the instruction disassembly for &lt;code&gt;run_on_new_stack&lt;/code&gt;. A good exercise would be to disassemble the function and convince yourself that the above choices are correct.&lt;/p&gt; &lt;p&gt;We can now create an instance of our &lt;code&gt;FrameID&lt;/code&gt; class and use this instance to create a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; class is the last piece of the unwinder process. We will store unwound register values into our &lt;code&gt;unwind_info&lt;/code&gt; object and return this to GDB in order to claim this frame. However, we're not there just yet—for now, we're still printing a debug message and returning &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Adding unwound register values&lt;/h3&gt; &lt;p&gt;Having decided to claim this frame, and having created a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object, we need to store some unwound register values in our new &lt;code&gt;unwind_info&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;The unwound value of a register is the value a register had in the previous frame.&lt;/p&gt; &lt;p&gt;Locating the previous register values will involve understanding the assembler code for the function being unwound. You don't need to provide previous values for every register; in some cases, the previous value of a register will not be available at all, in which case nothing can be done.&lt;/p&gt; &lt;p&gt;To keep the complexity of this example down, we are only going to provide previous values for 3 registers, the program counter, &lt;code&gt;%rsp&lt;/code&gt;, and &lt;code&gt;%rbp&lt;/code&gt;. These registers are enough to allow GDB to build a complete backtrace on x86-64. Once you've seen how these registers are supported, extending the example to support other registers as needed should be easy enough.&lt;/p&gt; &lt;p&gt;As before, let's just update &lt;code&gt;runon-unwind.py&lt;/code&gt;, and discuss the changes afterwards:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout the # frame, no matter what $pc we stop at. We use the $sp value # for the previous frame (this was our $sp on frame entry), # and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) # Calculate the previous register values. Select the correct # previous value for $rbp based on where we are in the # function. if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8)) # We use the previous $sp value in our frame-id, which is handy! prev_rsp = frame_sp # The previous $pc is always on the original (incoming) stack. prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp)) # And store the previous values into our cache. unwind_info.add_saved_register("rsp", prev_rsp) unwind_info.add_saved_register("rbp", prev_rbp) unwind_info.add_saved_register("pc", prev_pc) # Return the cache for GDB to use. return unwind_info gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The most important part of this new version are the three calls to &lt;code&gt;unwind_info.add_saved_register&lt;/code&gt;; this is how we record the unwound register values. The first argument to these calls is the name of the register we are recording, and the second argument is the value that register had in the previous frame.&lt;/p&gt; &lt;p&gt;The three registers we record are &lt;code&gt;pc&lt;/code&gt;, &lt;code&gt;rsp&lt;/code&gt;, and &lt;code&gt;rbp&lt;/code&gt;. Figuring out the previous value for the first two registers is pretty easy. We already have the previous &lt;code&gt;rsp&lt;/code&gt; value, remember, this is what we used for our frame-id so that we can reuse that value here.&lt;/p&gt; &lt;p&gt;Recall from our earlier stack diagrams; the return address in &lt;code&gt;main&lt;/code&gt; was the last thing stored on the original stack, this is what the previous stack-pointer points at, so we can load the return address with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And this just leaves the previous &lt;code&gt;rbp&lt;/code&gt; value. Just like we found the previous &lt;code&gt;rsp&lt;/code&gt; value earlier, the current instruction within &lt;code&gt;run_on_new_stack&lt;/code&gt; will determine the location of the previous &lt;code&gt;rbp&lt;/code&gt; value. Initially the previous value is in the &lt;code&gt;rbp&lt;/code&gt; register, but we store this previous value to the new stack before calling &lt;code&gt;func&lt;/code&gt;. And so, to find the correct previous value, we need to switch based on the program-counter value, which we do with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last update is to remove the debug message that we have been printing until now, and instead of returning &lt;code&gt;None&lt;/code&gt;, return our &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object &lt;code&gt;unwind_info&lt;/code&gt;. This tells GDB that our unwinder has claimed this frame. GDB will use the previous register values stored within &lt;code&gt;unwind_info&lt;/code&gt; when it needs to unwind through this frame.&lt;/p&gt; &lt;p&gt;So, for the last time, let's try our unwinder in GDB:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runon-unwind.py (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00000000004011e0 in main () at demo.c:33 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And success! We can now unwind through &lt;code&gt;run_on_new_stack&lt;/code&gt; back to &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Summary and conclusions&lt;/h3&gt; &lt;p&gt;Writing custom stack unwinders is not trivial; it requires a good understanding of the function being unwound and the architecture the unwinder is being written for. There is more to GDB's unwinder API than has been discussed in this brief introduction. The full details can all be found in the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;documentation&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" title="Debugging in GDB: Create custom stack winders"&gt;Debugging in GDB: Create custom stack winders&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Burgess</dc:creator><dc:date>2023-06-19T07:00:00Z</dc:date></entry><entry><title type="html">Life in First Principles</title><link rel="alternate" href="http://www.ofbizian.com/2023/06/life-in-first-principles.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2023/06/life-in-first-principles.html</id><updated>2023-06-16T07:27:00Z</updated><content type="html">Let's express life through its finite ingredients. There are three resources in life that everything else depends on. Every time you waste any of them, they're gone forever. These are time, energy, and focus. TIME Time is the one variable that nobody has any control over. There are 24 hours in a day, 365 days in a year. Time offers the same equal consistency to everybody, but at different lengths. We are born, we live, and we die. All you can do is maximise the other variables in the time given to you, in a way meaningful to you. ENERGY Being alive is a prerequisite, but not sufficient to reach happiness. Given a lifetime, to maximise your purpose and happiness, depends on your energy levels. Energy is the ability to do things, physically or mentally. Having a body sufficiently healthy that will enable you to pursue your purpose. For some, this can be a physically strong body, having a good sleep, healthy diet, and regular exercise. For others, it can be sufficient to be able to get up from the bed and hold a pen. And for some even the ability to express your thoughts through a computer device (such as Stephen Hawking). Energy levels vary from person to person, but so are the energy needs. Energy is not a "have or have not" constant like life is, it is rather a variable that tends that changes every moment, and tends to go down with age. Energy is the multiplier that lets you get the best out of the time given to you. FOCUS Being lucky to be alive, and having sufficient energy, gives the optionality to spend your attention in many ways. Focus is about how we use our time and energy in a directed way. It is the ability to concentrate our attention in a direction that makes us happy, or spread and waste in the universe in a way benefiting others or nobody. Focus is the variable that we have most control over, and the variable that has the biggest power to change our life. Used in a purposeful way, even in short lifespan and limited energy levels, it has led to personal fulfilments, or human achievements that are remembered throughout millennials. Used purposelessly, can lead to wasted long life full of energy, and many regrets in a death bed. THE HAPPINESS FORMULA If time is a yes/no constant, and the energy level is a multiplier for every moment, then focus is the exponent of all. Every moment, we are alive, we have a certain energy level that we can use for something purposeful or waste for nothing. Then we have recharge again. Every moment we have the ability to focus our energy to things that matter to us, or waste it aimlessly. Life happiness is the sum of all moments we had, with sufficient energy to help us focus on things that makes us happy. Happiness is the sum of all finite moments where we focus our energy towards our purpose Every time we waste these finite resources, they're gone forever. Make sure you are alive first, healthy and energised second, and also focused on what makes you happy. These variables build on top of each other and require a delicate balance. Focus too much on one thing, and you may lose your life in an instant. Ignore your health, and your energy levels will suffer hindering the ability to focus. Do everything right, and still a meteor can hit you and end it all. There is no guarantee, or fairness in any of these, only the awareness of its working. This formula is re presentation of how these finite resources can be transformed into happiness in the equation called life.</content><dc:creator>Unknown</dc:creator></entry><entry><title>Quarkus 3.1.2.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-1-2-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-1-2-final-released/</id><updated>2023-06-16T00:00:00Z</updated><published>2023-06-16T00:00:00Z</published><summary type="html">We released Quarkus 3.1.2.Final, the second maintenance release of our 3.1 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.1. If you are not already using 3.1, please refer to the Quarkus 3.1 migration guide. And if you...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-06-16T00:00:00Z</dc:date></entry><entry><title>How to use Ansible to create a VM on Azure</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure" /><author><name>Deepankar Jain</name></author><id>32865531-f2b4-4927-ab77-8d80f69d9656</id><updated>2023-06-15T18:00:00Z</updated><published>2023-06-15T18:00:00Z</published><summary type="html">&lt;p&gt;In our &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli#"&gt;previous article&lt;/a&gt;, we explored how to use the Red Hat Ansible Automation Platform's CLI to create a virtual machine (VM) in Microsoft Azure. This time, we'll take things a step further and leverage the power of the Ansible Automation Platform to automate the process. The Ansible Automation Platform is a powerful tool that enables you to manage your infrastructure more efficiently, with less manual intervention.&lt;/p&gt; &lt;p&gt;Follow the series:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli#"&gt;How to automate VM creation on Azure with Ansible CLI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 2: How to use Ansible to create a VM on Azure&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;How to use Ansible to create a VM on Azure via workflow&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;By using the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt;, we can create a streamlined process for deploying VMs in Azure, reducing errors and saving time. In this article, we'll dive into the details of how to use the Ansible Automation Platform to create VMs in Azure.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;1. The operating system on your local machine must be Red Hat Enterprise Linux (&lt;a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux"&gt;RHEL&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;2. Before you can complete any of the following tasks, you must create a &lt;a href="https://access.redhat.com/terms-based-registry/"&gt;registry service account&lt;/a&gt;. To log in to service account (SA), you'll need to use a container runtime such as Podman or Docker. &lt;a href="https://podman.io/"&gt;Podman&lt;/a&gt; is a powerful and secure open-source tool that can be used as an alternative to Docker, with the added benefits of not requiring a daemon to run containers and having a more lightweight footprint. We recommend &lt;a href="https://podman.io/getting-started/installation"&gt;installing Podman&lt;/a&gt;. This &lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools"&gt;article&lt;/a&gt; explains how Podman offers a more efficient container experience.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman login registry.redhat.io Username: {REGISTRY-SERVICE-ACCOUNT-USERNAME} Password: {REGISTRY-SERVICE-ACCOUNT-PASSWORD} Login Succeeded!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once we are successful in logging into the SA, we need to create a container image by using a Dockerfile containing the following context:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;FROM registry.redhat.io/ansible-automation-platform-22/ee-supported-rhel8:latest RUN pip3 install 'ansible[azure]' RUN ansible-galaxy collection install azure.azcollection RUN pip3 install -r ~/.ansible/collections/ansible_collections/azure/azcollection/requirements-azure.txt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Build an image using Podman as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman build -t &lt;image-name&gt;.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Push the image into the container image registry. Log in to the private container image registry using the &lt;code&gt;podman login&lt;/code&gt; command before pushing.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman push &lt;image-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;div&gt;Add the image name in the execution environment, as shown in Figure 1. You can also use the &lt;a href="https://developers.redhat.com/learning/learn%3Aansible/resource/resources%3Aget-started-ansible-automation-platform-builder"&gt;execution environment builder&lt;/a&gt; to create a custom execution environment. &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_11-58-11.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_11-58-11.png?itok=xXki-AuG" width="600" height="295" alt="A screenshot of the execution environment page of Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The execution environment page of Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;3. Create an &lt;a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"&gt;Azure Active Directory&lt;/a&gt; (Azure AD) account, a service principal, and give permissions in Azure.&lt;/p&gt; &lt;p&gt;4. Follow these &lt;a href="https://learn.microsoft.com/en-us/azure/industry/training-services/microsoft-community-training/frequently-asked-questions/generate-new-clientsecret-link-to-key-vault"&gt;instructions&lt;/a&gt; to generate a client secret for the service principal. &lt;/p&gt; &lt;p&gt;5. Click &lt;strong&gt;Credentials&lt;/strong&gt; under &lt;strong&gt;Resources &lt;/strong&gt;and select &lt;strong&gt;Microsoft Azure Resource Manager.&lt;/strong&gt; Then, enter your subscription_id, tenant id, client id, secret, username, and password (Figure 2).&lt;/p&gt; &lt;/div&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-34-59.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-34-59.png?itok=aXDBdtnd" width="600" height="317" alt="A screenshot of the Azure credentials page in Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Enter your Azure credentials in Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating and configuring the project&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Install the Ansible Automation Platform by following these &lt;a href="https://developers.redhat.com/articles/2023/01/01/how-install-red-hat-ansible-automation-platform-rhel-9"&gt;instructions&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Log in to the Ansible Automation Platform Portal in browser.&lt;/li&gt; &lt;li aria-level="1"&gt;Navigate to the &lt;strong&gt;Projects&lt;/strong&gt; tab under &lt;strong&gt;Resources&lt;/strong&gt; in the left pane.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Add&lt;/strong&gt; to create a new project.&lt;/li&gt; &lt;li aria-level="1"&gt;Enter a name for the project and choose &lt;strong&gt;Git&lt;/strong&gt; as the source control type with the URL: https://github.com/redhat-developer-demos/ansible-automation-platform-cloud-solutions in the &lt;strong&gt;Source Control URL&lt;/strong&gt; field. If you're interested in checking out the Ansible Playbooks, you can find them on &lt;a href="https://github.com/redhat-developer-demos/ansible-automation-platform-cloud-solutions"&gt;Github&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Save the changes and wait for the operation to complete successfully (Figure 3).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-37-05.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-37-05.png?itok=5w6HVdXy" width="600" height="129" alt="A screenshot of the source control project in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The source control in the project in Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating and configuring the job template&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Go to the &lt;strong&gt;Templates&lt;/strong&gt; tab under resources in the left pane, click the &lt;strong&gt;add&lt;/strong&gt; button, and select &lt;strong&gt;Job template&lt;/strong&gt; from the options.&lt;/li&gt; &lt;li aria-level="1"&gt;Enter a name for the job you want to create, select the &lt;strong&gt;Demo-Inventory&lt;/strong&gt; or &lt;strong&gt;Default inventory&lt;/strong&gt; in the &lt;strong&gt;Inventory&lt;/strong&gt; section.&lt;/li&gt; &lt;li aria-level="1"&gt;In the &lt;strong&gt;Project&lt;/strong&gt; section, click on the project name you previously created and select the Azure/create_vm_job_template.yml file.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Configuring the variables and execution environment&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Variables&lt;/strong&gt; section and add the variables as follows:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-yaml"&gt;--- vm_name: "Test-Ansible" vm_size: "Standard_B1ls" vm_image: "RedHat:RHEL:8-LVM:latest" vm_username: "testansible" vm_password: "my-password@1234" rg_name: "test-ansible" vnet_name: "test-ansible" subnet_name: "test-ansible" location: "centralindia" offer: “CentOS” publisher: “OpenLogic” sku: “7.5” version: ”latest”&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Select the credentials you previously created under the selected category (Figure 4).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-40-15.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-40-15.png?itok=dfwqZin1" width="600" height="259" alt="A screenshot of the form for selecting pre-configured Azure credentials." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4 : Select pre-configured Azure credentials for secure authentication.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Select the execution environment you previously created (Figure 5).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-42-54.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-42-54.png?itok=QISI_KtX" width="600" height="408" alt="Figure 4: Selecting pre-configured execution environment" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Selecting the pre-configured execution environment.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Save your changes by clicking the &lt;strong&gt;Save&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Launch&lt;/strong&gt; button to launch the job.&lt;/li&gt; &lt;li&gt;Once the job is launched using the Ansible Automation Platform, the system will generate an output, as shown in Figure 6. The output displays the job status and the progress of the VM creation process.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-06-15_at_12.04.09_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-06-15_at_12.04.09_pm.png?itok=LWz4-Zuq" width="600" height="281" alt="A screenshot of the output from the job in the Ansible Automation Platform console." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: The output from the job in the Ansible Automation Platform console.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;You can&lt;span&gt; check the virtual machine by navigating to the Azure portal&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to use the Ansible Automation Platform to create a VM in Microsoft Azure. You learned how the Ansible Automation Platform can streamline the process of deploying VMs in Azure, making it more efficient and less error-prone. By using the power of automation, we can save time and free up resources to focus on other important tasks.&lt;/p&gt; &lt;p&gt;You can explore more of what the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt; has to offer by &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;downloading it&lt;/a&gt;. Additionally, there are &lt;a href="https://developers.redhat.com/e-books"&gt;e-books&lt;/a&gt; such as, &lt;a href="https://developers.redhat.com/e-books/automation-at-the-edge"&gt;Automation at the edge&lt;/a&gt;, &lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;Choosing an Automation Tool&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;An IT executive's guide to automation&lt;/a&gt;. A cheat sheet is also available for &lt;a href="https://developers.redhat.com/cheat-sheets/wifi-automation-ansible-and-sd-wan-meraki-cheat-sheet"&gt;WiFi automation with Ansible and SD&lt;/a&gt; that provides a quick reference for network automation tasks.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;final article&lt;/a&gt; in this 3-part series will demonstrate how to simplify the process of creating VMs in Azure by using workflow templates. Workflow templates can help standardize the process of creating VMs and reduce the amount of manual intervention required. &lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure" title="How to use Ansible to create a VM on Azure"&gt;How to use Ansible to create a VM on Azure&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-06-15T18:00:00Z</dc:date></entry><entry><title>How to automate VM creation on Azure with Ansible CLI</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli" /><author><name>Deepankar Jain</name></author><id>54f40aea-f407-4a04-a9c5-da85ffe5427a</id><updated>2023-06-15T07:00:00Z</updated><published>2023-06-15T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will demonstrate how to use the Red Hat Ansible Automation Platform command-line interface (CLI) to create a virtual machine on Microsoft Azure. We will walk you through the steps required to get started with Ansible Automation Platform and Azure, including setting up the necessary resources and creating a VM using the Azure module and Ansible Automation Platform.&lt;/p&gt; &lt;p&gt;This series covers the end-to-end process of creating a Virtual Machine(VM) on Azure using Ansible Automation Platform. This 3-part series includes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Part 1: How to automate VM creation on Azure with Ansible CLI&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure"&gt;How to use Ansible to create a VM on Azure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;How to use Ansible to create a VM on Azure via workflow&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;By the end of this article, you'll have a better understanding of how to use Ansible Automation Platform CLI to manage VMs and how this streamlines your infrastructure management workflows.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Before you begin this tutorial, complete the following:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Make sure &lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"&gt;Ansible Automation Platform&lt;/a&gt; is installed on your system.&lt;/li&gt; &lt;li aria-level="1"&gt;Create a Microsoft Azure account.&lt;/li&gt; &lt;li aria-level="1"&gt;Install &lt;a href="https://galaxy.ansible.com/azure/azcollection"&gt;Ansible content collection for Azure&lt;/a&gt; on your system.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How to use the Ansible CLI to create a VM&lt;/h2&gt; &lt;p&gt;Follow these steps to create a virtual machine using Ansible Automation Platform CLI:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"&gt;Create a service principal and give permissions in Azure&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/industry/training-services/microsoft-community-training/frequently-asked-questions/generate-new-clientsecret-link-to-key-vault"&gt;Generate the client secret for service principal&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;You should now have a&lt;strong&gt; subscriptionid, tenantid, clientid and client secret &lt;/strong&gt;that you can use to access your Azure Account and launch a VM.&lt;/li&gt; &lt;li aria-level="1"&gt;Open any text editor on your local machine and copy the following yml into it:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-yaml"&gt;--- # Get facts for the user - name: Create a Virtual Machine on Azure Using Ansible hosts: localhost vars: vm_name: "Test-Ansible" vm_size: "Standard_B1ls" vm_image: "RedHat:RHEL:8-LVM:latest" vm_username: "testansible" vm_password: "my-password@1234" rg_name: "test-ansible" vnet_name: "test-ansible" subnet_name: "test-ansible" location: "centralindia" subscription_id: &lt;YOUR SUBSCRIPTION ID&gt; tenant: &lt;YOUR TENANT ID&gt; client_id: &lt;YOUR CLIENT ID&gt; secret: &lt;YOUR SECRET&gt; tasks: - name: Create a Resource Group azure.azcollection.azure_rm_resourcegroup: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" name: "{{ rg_name }}" location: "{{ location }}" register: rg - name: Create a Virtual Network azure.azcollection.azure_rm_virtualnetwork: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vnet_name }}" address_prefixes: "10.0.0.0/16" register: vnet - name: Create a subnet azure.azcollection.azure_rm_subnet: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" virtual_network_name: "{{ vnet_name }}" name: "{{ subnet_name }}" address_prefix: "10.0.0.0/24" register: subnet - name: Create a public IP address azure.azcollection.azure_rm_publicipaddress: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" allocation_method: static name: "{{ vm_name }}-public-ip" register: public_ip - name: Create a network security group and configure the security group azure.azcollection.azure_rm_securitygroup: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}-nsg" rules: - name: "AllowSSH" protocol: Tcp direction: Inbound priority: 1000 access: Allow source_address_prefix: "*" source_port_range: "*" destination_port_range: "22" destination_address_prefix: "*" register: nsg - name: Create a Virtual Network Interface Card azure.azcollection.azure_rm_networkinterface: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}-nic" virtual_network: "{{ vnet_name }}" subnet_name: "{{ subnet_name }}" public_ip_name: "{{ vm_name }}-public-ip" security_group: "{{ vm_name }}-nsg" - name: Create a vm_image azure.azcollection.azure_rm_virtualmachine: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}" vm_size: "{{ vm_size }}" admin_username: "{{ vm_username }}" admin_password: "{{ vm_password }}" image: offer: "CentOS" publisher: "OpenLogic" sku: "7.5" version: "latest" os_disk_caching: ReadWrite os_disk_name: "{{ vm_name }}-os-disk" network_interface_names: - "{{ vm_name }}-nic" network_interfaces: - name: "{{ vm_name }}-nic" properties: primary: True availability_set: null ssh_public_keys: [] ssh_password_enabled: true &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Save and close the file.&lt;/li&gt; &lt;li aria-level="1"&gt;Open the terminal in the directory where the file is located on your local machine.&lt;/li&gt; &lt;li aria-level="1"&gt;Run the following command: &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-playbook &lt;filename&gt;.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;ansible-playbook -i inventory azure_cli.yml PLAY [Create a Virtual Machine on Azure Using Ansible] ************************************************************************************************************************************************************ TASK [Gathering Facts] ******************************************************************************************************************************************************************************************** ok: [localhost] TASK [Create a Resource Group] ************************************************************************************************************************************************************************************ changed: [localhost] TASK [Create a Virtual Network] *********************************************************************************************************************************************************************************** changed: [localhost] TASK [Create a subnet] ******************************************************************************************************************************************************************************************** changed: [localhost] TASK [Create a public IP address] ********************************************************************************************************************************************************************************* changed: [localhost] TASK [Create a network security group and configure the security group] ******************************************************************************************************************************************* changed: [localhost] TASK [Create a Virtual Network Interface Card] ******************************************************************************************************************************************************************** [DEPRECATION WARNING]: Setting ip_configuration flatten is deprecated and will be removed. Using ip_configurations list to define the ip configuration. This feature will be removed in version [2, 9]. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. changed: [localhost] TASK [Create a vm_image] ****************************************************************************************************************************************************************************************** [WARNING]: Both option network_interface_names and its alias network_interfaces are set. changed: [localhost] PLAY RECAP ******************************************************************************************************************************************************************************************************** localhost : ok=8 changed=7 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 &lt;/code&gt;&lt;/pre&gt; Figure 1 shows the the Microsoft Azure VM. &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-26_13-04-45.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-26_13-04-45.png?itok=57gOPDNO" width="600" height="297" alt="A screenshot of the Microsoft Azure virtual machine." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The Microsoft Azure virtual machine.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to create a VM using &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Ansible Automation Platform&lt;/a&gt;. If you followed this step-by-step guide, you should now have a good understanding of how to use Ansible Automation Platform to automate the creation of a VM.&lt;/p&gt; &lt;p&gt;In our &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure"&gt;next article&lt;/a&gt; in this series, we will explore how &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt; further eases the process of creating VMs by defining infrastructure as code, tracking infrastructure changes, and enforcing compliance policies.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Get started&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; with Ansible Automation Platform by exploring interactive hands-on labs. &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://developers.redhat.com/products/ansible/download"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Download Ansible Automation Platform&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; at no cost and begin your automation journey. You can refer to &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;An IT executive's guide to automation&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; e-book for a better understanding of the Ansible Automation Platform.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli" title="How to automate VM creation on Azure with Ansible CLI"&gt;How to automate VM creation on Azure with Ansible CLI&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-06-15T07:00:00Z</dc:date></entry><entry><title type="html">Java 21 Unnamed Classes and Instance Main Methods</title><link rel="alternate" href="https://www.mastertheboss.com/java/java-21-unnamed-classes-and-instance-main-methods/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java/java-21-unnamed-classes-and-instance-main-methods/</id><updated>2023-06-13T10:38:54Z</updated><content type="html">Java 21 introduces two language core features: Unnamed Java Classes and a new launch protocol which allows running Java classes in a simpler format. In this article we will cover in detail these new features explaining how they can simplify your daily Java coding. Java 21 introduces two core features that will simplify the coding ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Quarkus Newsletter #33 - June</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-newsletter-33/&#xA;            " /><author><name>James Cobb (https://twitter.com/insectengine)</name></author><id>https://quarkus.io/blog/quarkus-newsletter-33/</id><updated>2023-06-13T00:00:00Z</updated><published>2023-06-13T00:00:00Z</published><summary type="html">Check out the June Newsletter. Read "A Guide to the Quarkus 3 Azure Functions Extension: Bootstrap Java Microservices with Ease" by Daniel Oh &amp; Erik Costlow and to learn how Quarkus integrates Java microservices into Azure Functions with an improved developer experience. Check out "Quarkus: Java revisited!" by Willem Meints...</summary><dc:creator>James Cobb (https://twitter.com/insectengine)</dc:creator><dc:date>2023-06-13T00:00:00Z</dc:date></entry></feed>
